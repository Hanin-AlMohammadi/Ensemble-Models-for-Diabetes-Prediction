{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14e9e474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\H\\Downloads\\diabetes.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aea1a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display general information about the dataset\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fdb4c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bd685f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05b5c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop(columns='Outcome')\n",
    "y = data['Outcome']\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bf233a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27a4892c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection (Logistic Regression): 8\n",
      "Number of features after selection (Logistic Regression): 2\n",
      "Selected features (Logistic Regression): Index(['Glucose', 'BMI'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=200, solver='saga')\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "sfm_log_reg = SelectFromModel(log_reg, threshold='mean', prefit=True)\n",
    "X_train_selected_log_reg = sfm_log_reg.transform(X_train_scaled)\n",
    "X_test_selected_log_reg = sfm_log_reg.transform(X_test_scaled)\n",
    "\n",
    "# Print the number of features before and after selection\n",
    "print(\"Number of features before selection (Logistic Regression):\", X_train_scaled.shape[1])\n",
    "print(\"Number of features after selection (Logistic Regression):\", X_train_selected_log_reg.shape[1])\n",
    "\n",
    "# Print the selected features' names\n",
    "selected_features_log_reg = X.columns[sfm_log_reg.get_support()]\n",
    "print(\"Selected features (Logistic Regression):\", selected_features_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9af0468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection: 8\n",
      "Number of features after selection: 3\n",
      "Selected features (Logistic Regression): Index(['Glucose', 'BMI'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "sfm = SelectFromModel(clf, threshold='mean', prefit=True)\n",
    "X_train_selected = sfm.transform(X_train_scaled)\n",
    "X_test_selected = sfm.transform(X_test_scaled)\n",
    "\n",
    "# Print the number of features before and after selection\n",
    "print(\"Number of features before selection:\", X_train_scaled.shape[1])\n",
    "print(\"Number of features after selection:\", X_train_selected.shape[1])\n",
    "\n",
    "# Print the selected features' names\n",
    "selected_features_log_reg = X.columns[sfm_log_reg.get_support()]\n",
    "print(\"Selected features (Logistic Regression):\", selected_features_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb5cb2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection (Decision Tree): 8\n",
      "Number of features after selection (Decision Tree): 2\n",
      "Selected features (Decision Tree): Index(['Glucose', 'Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=4)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "sfm_dt = SelectFromModel(dt, threshold='mean', prefit=True)\n",
    "X_train_selected_dt = sfm_dt.transform(X_train_scaled)\n",
    "X_test_selected_dt = sfm_dt.transform(X_test_scaled)\n",
    "\n",
    "# Print the number of features before and after selection\n",
    "print(\"Number of features before selection (Decision Tree):\", X_train_scaled.shape[1])\n",
    "print(\"Number of features after selection (Decision Tree):\", X_train_selected_dt.shape[1])\n",
    "\n",
    "# Print the selected features' names\n",
    "selected_features_dt = X.columns[sfm_dt.get_support()]\n",
    "print(\"Selected features (Decision Tree):\", selected_features_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe414a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before selection (SVM): 8\n",
      "Number of features after selection (SVM): 2\n",
      "Selected features (SVM): Index(['Glucose', 'BMI'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using SVM\n",
    "svm = SVC(C=2, kernel='linear')\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "sfm_svm = SelectFromModel(svm, threshold='mean', prefit=True)\n",
    "X_train_selected_svm = sfm_svm.transform(X_train_scaled)\n",
    "X_test_selected_svm = sfm_svm.transform(X_test_scaled)\n",
    "\n",
    "# Print the number of features before and after selection\n",
    "print(\"Number of features before selection (SVM):\", X_train_scaled.shape[1])\n",
    "print(\"Number of features after selection (SVM):\", X_train_selected_svm.shape[1])\n",
    "\n",
    "# Print the selected features' names\n",
    "selected_features_svm = X.columns[sfm_svm.get_support()]\n",
    "print(\"Selected features (SVM):\", selected_features_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e47a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.7619047619047619\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       157\n",
      "           1       0.68      0.49      0.57        74\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.73      0.69      0.70       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model with selected features\n",
    "log_reg_model = LogisticRegression(max_iter=200, solver='saga')\n",
    "log_reg_model.fit(X_train_selected_log_reg, y_train)\n",
    "y_pred_log_reg = log_reg_model.predict(X_test_selected_log_reg)\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "\n",
    "print(\"Logistic Regression Test Accuracy:\", log_reg_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "205c6ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy with Selected Features: 0.7792207792207793\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       157\n",
      "           1       0.71      0.53      0.60        74\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.76      0.71      0.73       231\n",
      "weighted avg       0.77      0.78      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest model with selected features\n",
    "rf_model_selected = RandomForestClassifier(n_estimators=150, max_depth=7, min_samples_split=10, min_samples_leaf=4)\n",
    "rf_model_selected.fit(X_train_selected, y_train)\n",
    "y_pred_rf_selected = rf_model_selected.predict(X_test_selected)\n",
    "rf_selected_accuracy = accuracy_score(y_test, y_pred_rf_selected)\n",
    "\n",
    "print(\"Random Forest Test Accuracy with Selected Features:\", rf_selected_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_rf_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "277fb0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Test Accuracy: 0.7445887445887446\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       157\n",
      "           1       0.63      0.49      0.55        74\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.68      0.69       231\n",
      "weighted avg       0.73      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree model with selected features\n",
    "dt_model = DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=4)\n",
    "dt_model.fit(X_train_selected_dt, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_selected_dt)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Test Accuracy:\", dt_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f8d0adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Test Accuracy: 0.7662337662337663\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       157\n",
      "           1       0.69      0.49      0.57        74\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.74      0.69      0.71       231\n",
      "weighted avg       0.76      0.77      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model with selected features\n",
    "svm_model = SVC(C=2, kernel='linear')\n",
    "svm_model.fit(X_train_selected_svm, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_selected_svm)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Test Accuracy:\", svm_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ce7b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Test Accuracy: 0.7402597402597403\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       157\n",
      "           1       0.62      0.49      0.55        74\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.67      0.68       231\n",
      "weighted avg       0.73      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging with Decision Tree\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=0)\n",
    "bagging.fit(X_train_selected, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test_selected)\n",
    "bagging_accuracy = accuracy_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(\"Bagging Test Accuracy:\", bagging_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11c57f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Test Accuracy: 0.7532467532467533\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       157\n",
      "           1       0.65      0.49      0.56        74\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.68      0.69       231\n",
      "weighted avg       0.74      0.75      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boosting with Gradient Boosting\n",
    "boosting = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "boosting.fit(X_train_selected, y_train)\n",
    "y_pred_boosting = boosting.predict(X_test_selected)\n",
    "boosting_accuracy = accuracy_score(y_test, y_pred_boosting)\n",
    "\n",
    "print(\"Boosting Test Accuracy:\", boosting_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_boosting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc33564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Test Accuracy: 0.7662337662337663\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       157\n",
      "           1       0.69      0.49      0.57        74\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.74      0.69      0.71       231\n",
      "weighted avg       0.76      0.77      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking with multiple models\n",
    "estimators = [\n",
    "    ('log_reg', LogisticRegression(max_iter=200, solver='saga')),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=7, min_samples_split=10, min_samples_leaf=4)),\n",
    "    ('svm', SVC(C=2, kernel='linear', probability=True))\n",
    "]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(n_estimators=100, random_state=0))\n",
    "stacking.fit(X_train_selected, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test_selected)\n",
    "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
    "\n",
    "print(\"Stacking Test Accuracy:\", stacking_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "22a2d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Test Accuracy: 0.7662337662337663\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       157\n",
      "           1       0.70      0.47      0.56        74\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.74      0.69      0.70       231\n",
      "weighted avg       0.76      0.77      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier with multiple models\n",
    "voting = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting.fit(X_train_selected, y_train)\n",
    "y_pred_voting = voting.predict(X_test_selected)\n",
    "\n",
    "voting_accuracy = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"Voting Test Accuracy:\", voting_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_voting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a68ece00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.joblib']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the final model\n",
    "model_classification = 'final_model.joblib'\n",
    "dump(ensemble_model, model_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5711f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the final model and test it on new data\n",
    "loaded_model = load(model_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11d41c58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Test Accuracy: 0.7619047619047619\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       157\n",
      "           1       0.69      0.47      0.56        74\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.73      0.69      0.70       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model on new data (same data used as examples)\n",
    "y_pred_loaded = loaded_model.predict(X_test_selected)\n",
    "loaded_model_accuracy = accuracy_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(\"Loaded Model Test Accuracy:\", loaded_model_accuracy)\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fa1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
